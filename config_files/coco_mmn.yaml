DATA:
  train_name: coco
  test_name: default     # test model on different data
  train_split: 0
  test_split: default    # test model on different data
  data_root: /coco/
  train_list: lists/coco/train.txt
  val_list: lists/coco/val.txt
  num_classes_tr: 2    # Counting background for training
  num_classes_val: 20
  use_split_coco: True
  workers: 2
  image_size: 473
  padding_label: 255
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  scale_min: 0.5
  scale_max: 2.0
  rot_min: -10
  rot_max: 10
  augmentations: ['hor_flip', 'resize_np']

TRAIN:
  ckpt_path: checkpoints/
  batch_size: 1
  epochs: 5
  save_models: False
  cls_lr: 0.025
  trans_lr: 0.002
  scale_lr: 1.0
  mixup: False
  lr_stepsize: 30       # LR scheduler
  momentum: 0.9
  gamma: 0.1            # LR scheduler
  nesterov: True
  weight_decay: 0.0001
  main_optim: SGD
  scheduler: cosine
  milestones: [40, 70]
  log_iter: 2000
  adapt_iter: 100

MODEL:
  arch: resnet
  pretrained: False  # Means the backbone has been pre-trained
  bins: [1, 2, 3, 6]
  dropout: 0.1
  m_scale: False
  layers: 50
  bottleneck_dim: 512
  resume_weights: ./pretrained_models/

  temp: 20.0
  att_wt: 0.2
  aux: False     #  False or input weight of aux loss
  inner_loss_type: wt_ce
  loss_type: wt_dc   # 'wt_dc',  'wt_ce'
  agg: cat
  rmid: l34      # nr, l2, l4
  all_lr: l

  red_dim: False  # False or 512
  wa: False       # True or False

Classifier:
  dist: cosN
  cls_type: ooo


EVALUATION:
  shot: 1
  random_shot: False
  episodic: True
  norm_feat: True           # ?
  batch_size_val: 100
  manual_seed: 2021
  ckpt_used: best
  test_num: 1000
  FB_param_noise: 0
  smoothing: True
  n_runs: 1

Experiment:
  exp_name: l34_dice_cat_i100_lr025